import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt 
from sklearn.preprocessing import PolynomialFeatures 
from sklearn.linear_model import LinearRegression 
from sklearn.model_selection import train_test_split, cross_val_score 
from sklearn.metrics import mean_squared_error, r2_score 
data = pd.read_csv(r"D:\python\Ice_cream selling data.csv") 
X = data[['Temperature']].values # independent variable 
y = data['Ice Cream Units Sold'].values #dependent variable 
poly = PolynomialFeatures(degree=2) 
X_poly = poly.fit_transform(X) 
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, 
test_size=0.2, random_state=42) 
# Train the model 
model = LinearRegression() 
model.fit(X_train, y_train) 
y_train_pred = model.predict(X_train) 
y_test_pred = model.predict(X_test) 
train_mse = mean_squared_error(y_train, y_train_pred) 
test_mse = mean_squared_error(y_test, y_test_pred) 
train_r2 = r2_score(y_train, y_train_pred) 
test_r2 = r2_score(y_test, y_test_pred) 
print("Polynomial Regression Evaluation") 
print(f"Train MSE: {train_mse:.2f}, R2: {train_r2:.2f}") 
print(f"Test MSE: {test_mse:.2f}, R2: {test_r2:.2f}") 
# Cross Validation 
cv_scores = cross_val_score(model, X_poly, y, cv=5, scoring='r2') 
print("Cross-Validation R2 Scores:", cv_scores) 
print("Mean CV R2 Score:", np.mean(cv_scores)) 
print("") 
# Visualization 
X_range = np.linspace(0, 10, 100).reshape(-1, 1) 
X_range_poly = poly.transform(X_range) 
y_range_pred = model.predict(X_range_poly) 
plt.figure(figsize=(10, 6)) 
plt.scatter(X, y, color='gray', label='Data', alpha=0.6) 
plt.plot(X_range, y_range_pred, color='red', label='Polynomial 
Regression Fit') 
plt.xlabel('X') 
plt.ylabel('y') 
plt.title('Polynomial Regression Curve') 
plt.legend() 
plt.grid(True) 
plt.show()
